// S·ª≠ d·ª•ng Response API ti√™u chu·∫©n c·ªßa Next.js thay v√¨ th∆∞ vi·ªán ai
// v√¨ c√≥ th·ªÉ c√≥ s·ª± kh√¥ng t∆∞∆°ng th√≠ch gi·ªØa phi√™n b·∫£n
import { createClient, testOpenRouterConnection, MODEL_CONFIG } from "@/lib/openrouter-client"
import { searchDocuments } from "@/lib/knowledge"

export const runtime = "nodejs"
export const maxDuration = 60 // Gi·ªõi h·∫°n t·ªëi ƒëa cho g√≥i Hobby c·ªßa Vercel

export async function POST(req: Request) {
  try {
    console.log("API route handler started")

    // Ki·ªÉm tra API key
    const apiKey = process.env.OPENROUTER_API_KEY
    if (!apiKey) {
      console.error("OPENROUTER_API_KEY kh√¥ng ƒë∆∞·ª£c c·∫•u h√¨nh")
      return new Response(
        JSON.stringify({ error: "API key kh√¥ng ƒë∆∞·ª£c c·∫•u h√¨nh. Vui l√≤ng ki·ªÉm tra bi·∫øn m√¥i tr∆∞·ªùng." }),
        { status: 500, headers: { "Content-Type": "application/json" } },
      )
    }

    // Parse request body
    let messages
    try {
      const body = await req.json()
      messages = body.messages

      if (!messages || !Array.isArray(messages)) {
        console.error("Invalid request format: messages is missing or not an array")
        return new Response(
          JSON.stringify({ error: "ƒê·ªãnh d·∫°ng y√™u c·∫ßu kh√¥ng h·ª£p l·ªá. Thi·∫øu tr∆∞·ªùng messages ho·∫∑c kh√¥ng ph·∫£i l√† m·∫£ng." }),
          { status: 400, headers: { "Content-Type": "application/json" } },
        )
      }

      console.log(`Received ${messages.length} messages`)
    } catch (error) {
      console.error("Error parsing request body:", error)
      return new Response(JSON.stringify({ error: "Kh√¥ng th·ªÉ ph√¢n t√≠ch n·ªôi dung y√™u c·∫ßu" }), {
        status: 400,
        headers: { "Content-Type": "application/json" },
      })
    }

    // L·∫•y tin nh·∫Øn cu·ªëi c√πng
    const lastMessage = messages[messages.length - 1].content
    console.log("Last message:", lastMessage.substring(0, 100) + (lastMessage.length > 100 ? "..." : ""))

    // T√¨m ki·∫øm th√¥ng tin li√™n quan t·ª´ c∆° s·ªü ki·∫øn th·ª©c
    let relevantDocs: Array<{content: string; source: string; similarity: number}> = []
    try {
      relevantDocs = await searchDocuments(lastMessage)
      console.log(`Found ${relevantDocs.length} relevant documents`)
    } catch (error) {
      console.error("Error searching documents:", error)
      // Ti·∫øp t·ª•c x·ª≠ l√Ω m√† kh√¥ng c√≥ t√†i li·ªáu li√™n quan
    }

    // T·∫°o context t·ª´ c√°c t√†i li·ªáu li√™n quan v·ªõi th√¥ng tin ngu·ªìn chi ti·∫øt h∆°n
    let context = ""
    if (relevantDocs.length > 0) {
      context = "Th√¥ng tin t·ª´ c∆° s·ªü ki·∫øn th·ª©c (H√ÉY S·ª¨ D·ª§NG TH√îNG TIN N√ÄY ƒê·ªÇ TR·∫¢ L·ªúI):\n\n" + 
        relevantDocs.map((doc, index) => {
          // T√≠nh ƒëi·ªÉm t∆∞∆°ng ƒë·ªìng theo thang 100
          const similarityScore = Math.round(doc.similarity * 100);
          return `[T√ÄI LI·ªÜU ${index + 1} - Ngu·ªìn: ${doc.source} - ƒê·ªô li√™n quan: ${similarityScore}%]\n${doc.content}`;
        }).join("\n\n")
    }

    // T·∫°o system prompt v·ªõi context
    const systemPrompt = `B·∫°n l√† tr·ª£ l√Ω AI c·ªßa Laya, m·ªôt h·ªá sinh th√°i tr·ªã li·ªáu k·∫øt h·ª£p ƒê√¥ng y, c√¥ng ngh·ªá v√† t√¢m tr√≠ h·ªçc.
    
    ${context ? context : "Kh√¥ng t√¨m th·∫•y th√¥ng tin li√™n quan trong c∆° s·ªü ki·∫øn th·ª©c."}
    
    H∆Ø·ªöNG D·∫™N B·∫ÆT BU·ªòC:
    1. N·∫øu c√≥ th√¥ng tin t·ª´ c∆° s·ªü ki·∫øn th·ª©c, B·∫ÆT BU·ªòC ph·∫£i s·ª≠ d·ª•ng ch√≠nh x√°c th√¥ng tin ƒë√≥ ƒë·ªÉ tr·∫£ l·ªùi. KH√îNG ƒê∆Ø·ª¢C t·ª± √Ω th√™m th√¥ng tin ho·∫∑c s√°ng t·∫°o n·ªôi dung kh√¥ng c√≥ trong t√†i li·ªáu.
    2. Tr√≠ch d·∫´n r√µ r√†ng ngu·ªìn th√¥ng tin khi tr·∫£ l·ªùi (v√≠ d·ª•: "Theo t√†i li·ªáu [t√™n t√†i li·ªáu]...").
    3. N·∫øu kh√¥ng c√≥ th√¥ng tin li√™n quan trong c∆° s·ªü ki·∫øn th·ª©c, h√£y n√≥i r·∫±ng b·∫°n kh√¥ng c√≥ th√¥ng tin v·ªÅ v·∫•n ƒë·ªÅ ƒë√≥ v√† ƒë·ªÅ ngh·ªã ng∆∞·ªùi d√πng li√™n h·ªá v·ªõi Mentor Laya ƒë·ªÉ ƒë∆∞·ª£c h·ªó tr·ª£.
    4. KH√îNG ƒê∆Ø·ª¢C t·∫°o ra c√°c th√¥ng tin sai l·ªách ho·∫∑c kh√¥ng c√≥ trong c∆° s·ªü ki·∫øn th·ª©c.
    
    Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, th√¢n thi·ªán v√† chuy√™n nghi·ªáp. S·ª≠ d·ª•ng emoji üåø khi n√≥i v·ªÅ s·∫£n ph·∫©m Laya v√† ‚ú® khi n√≥i v·ªÅ h·ªá th·ªëng Mentor.`

    // Ki·ªÉm tra k·∫øt n·ªëi v·ªõi OpenRouter tr∆∞·ªõc khi g·ª≠i y√™u c·∫ßu ch√≠nh
    let modelToUse = MODEL_CONFIG.modelId;
    
    try {
      console.log("Testing OpenRouter connection")
      const connectionTest = await testOpenRouterConnection()

      if (!connectionTest.success) {
        console.warn("OpenRouter connection test failed:", connectionTest.message)
        // Kh√¥ng tr·∫£ v·ªÅ l·ªói ngay l·∫≠p t·ª©c, thay v√†o ƒë√≥ s·∫Ω th·ª≠ ti·∫øp t·ª•c v·ªõi m√¥ h√¨nh m·∫∑c ƒë·ªãnh
        // ho·∫∑c m√¥ h√¨nh d·ª± ph√≤ng trong h√†m createChatCompletion
      } else {
        console.log("OpenRouter connection test successful")
        // S·ª≠ d·ª•ng m√¥ h√¨nh ƒë√£ ki·ªÉm tra th√†nh c√¥ng
        if (connectionTest.modelTested) {
          modelToUse = connectionTest.modelTested;
          console.log(`Using tested model: ${modelToUse}`);
        }
      }
    } catch (error) {
      console.error("Error testing OpenRouter connection:", error)
      // Ti·∫øp t·ª•c x·ª≠ l√Ω m·∫∑c d√π ki·ªÉm tra k·∫øt n·ªëi th·∫•t b·∫°i
    }

    console.log("Creating OpenRouter client")
    const openai = createClient()

    // T·∫°o stream response
    try {
      console.log(`Creating chat completion with model: ${modelToUse}`)
      
      // Thi·∫øt l·∫≠p timeout cho y√™u c·∫ßu
      const controller = new AbortController();
      const timeoutId = setTimeout(() => controller.abort(), MODEL_CONFIG.timeout);
      
      const response = await openai.chat.completions.create({
        model: modelToUse,
        messages: [{ role: "system", content: systemPrompt }, ...messages],
        stream: true,
        temperature: MODEL_CONFIG.temperature,
        max_tokens: MODEL_CONFIG.maxTokens,
      }, { signal: controller.signal })
      
      clearTimeout(timeoutId);

      console.log("Stream created successfully")

      // Tr·∫£ v·ªÅ streaming response s·ª≠ d·ª•ng Response API ti√™u chu·∫©n
      // Chuy·ªÉn ƒë·ªïi response th√†nh ReadableStream
      // V√¨ OpenAI SDK tr·∫£ v·ªÅ Stream<ChatCompletionChunk> m√† kh√¥ng ph·∫£i ReadableStream tr·ª±c ti·∫øp
      return new Response(
        new ReadableStream({
          async start(controller) {
            const encoder = new TextEncoder();
            
            try {
              // X·ª≠ l√Ω t·ª´ng chunk t·ª´ stream c·ªßa OpenAI
              for await (const chunk of response) {
                // L·∫•y n·ªôi dung vƒÉn b·∫£n t·ª´ chunk
                const text = chunk.choices[0]?.delta?.content || '';
                if (text) {
                  // ƒê·ªãnh d·∫°ng theo chu·∫©n SSE (Server-Sent Events)
                  const formattedChunk = `data: ${JSON.stringify({ text })}

`;
                  controller.enqueue(encoder.encode(formattedChunk));
                }
              }
              // K·∫øt th√∫c stream
              controller.enqueue(encoder.encode('data: [DONE]\n\n'));
              controller.close();
            } catch (error) {
              console.error('Error processing stream:', error);
              controller.error(error);
            }
          }
        }),
        {
          headers: {
            'Content-Type': 'text/event-stream',
            'Cache-Control': 'no-cache',
            'Connection': 'keep-alive'
          }
        }
      )
    } catch (error) {
      console.error("Error creating chat completion:", error)

      // Ph√¢n t√≠ch l·ªói ƒë·ªÉ cung c·∫•p th√¥ng b√°o l·ªói c·ª• th·ªÉ
      let errorMessage = "ƒê√£ x·∫£y ra l·ªói khi x·ª≠ l√Ω y√™u c·∫ßu. Vui l√≤ng th·ª≠ l·∫°i sau."
      let statusCode = 500

      if (error instanceof Error) {
        if (error.message.includes("API key")) {
          errorMessage = "API key kh√¥ng h·ª£p l·ªá ho·∫∑c ƒë√£ h·∫øt h·∫°n."
          statusCode = 401
        } else if (error.message.includes("model")) {
          errorMessage = `M√¥ h√¨nh ${MODEL_CONFIG.modelId} kh√¥ng kh·∫£ d·ª•ng ho·∫∑c kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£.`
          statusCode = 400
        } else if (error.message.includes("rate limit")) {
          errorMessage = "ƒê√£ v∆∞·ª£t qu√° gi·ªõi h·∫°n t·ªëc ƒë·ªô API. Vui l√≤ng th·ª≠ l·∫°i sau."
          statusCode = 429
        } else if (error.message.includes("timeout")) {
          errorMessage = "Y√™u c·∫ßu ƒë√£ h·∫øt th·ªùi gian ch·ªù. Vui l√≤ng th·ª≠ l·∫°i sau."
          statusCode = 504
        }
      }

      // Th·ª≠ ph∆∞∆°ng √°n d·ª± ph√≤ng - tr·∫£ v·ªÅ ph·∫£n h·ªìi kh√¥ng streaming
      try {
        console.log("Attempting fallback to non-streaming response")
        
        // Th·ª≠ v·ªõi c√°c m√¥ h√¨nh d·ª± ph√≤ng n·∫øu l·ªói li√™n quan ƒë·∫øn m√¥ h√¨nh
        let fallbackModelToUse = modelToUse;
        if (error instanceof Error && error.message.includes("model") && modelToUse === MODEL_CONFIG.modelId) {
          // Th·ª≠ v·ªõi m√¥ h√¨nh d·ª± ph√≤ng ƒë·∫ßu ti√™n
          if (MODEL_CONFIG.fallbackModels && MODEL_CONFIG.fallbackModels.length > 0) {
            fallbackModelToUse = MODEL_CONFIG.fallbackModels[0];
            console.log(`Trying fallback model: ${fallbackModelToUse}`);
          }
        }
        
        // Thi·∫øt l·∫≠p timeout cho y√™u c·∫ßu d·ª± ph√≤ng
        const fallbackController = new AbortController();
        const fallbackTimeoutId = setTimeout(() => fallbackController.abort(), 30000); // 30s timeout cho ph∆∞∆°ng √°n d·ª± ph√≤ng

        // T·∫°o ph·∫£n h·ªìi kh√¥ng streaming
        const fallbackResponse = await openai.chat.completions.create({
          model: fallbackModelToUse,
          messages: [{ role: "system", content: systemPrompt }, ...messages],
          stream: false,
          temperature: MODEL_CONFIG.temperature,
          max_tokens: MODEL_CONFIG.maxTokens / 2, // Gi·∫£m xu·ªëng ƒë·ªÉ tr√°nh timeout
        }, { signal: fallbackController.signal })
        
        clearTimeout(fallbackTimeoutId);

        const content = fallbackResponse.choices[0]?.message?.content || "Xin l·ªói, t√¥i kh√¥ng th·ªÉ tr·∫£ l·ªùi ngay b√¢y gi·ªù."
        console.log("Fallback response generated successfully")

        return new Response(JSON.stringify({ text: content }), {
          headers: { "Content-Type": "application/json" },
        })
      } catch (fallbackError) {
        console.error("Fallback response also failed:", fallbackError)

        // N·∫øu c·∫£ hai ph∆∞∆°ng √°n ƒë·ªÅu th·∫•t b·∫°i, tr·∫£ v·ªÅ th√¥ng b√°o l·ªói
        return new Response(
          JSON.stringify({
            error: errorMessage,
            details: error instanceof Error ? error.message : "Unknown error",
          }),
          {
            status: statusCode,
            headers: { "Content-Type": "application/json" },
          },
        )
      }
    }
  } catch (error) {
    console.error("Unhandled error in chat API:", error)
    return new Response(
      JSON.stringify({
        error: "ƒê√£ x·∫£y ra l·ªói kh√¥ng x√°c ƒë·ªãnh khi x·ª≠ l√Ω y√™u c·∫ßu",
        details: error instanceof Error ? error.message : "Unknown error",
      }),
      {
        status: 500,
        headers: { "Content-Type": "application/json" },
      },
    )
  }
}

// Th√™m endpoint ƒë·ªÉ ki·ªÉm tra tr·∫°ng th√°i API
export async function GET() {
  try {
    const connectionTest = await testOpenRouterConnection()

    // Ki·ªÉm tra c√°c t·ªáp ki·∫øn th·ª©c
    let knowledgeStatus = "unknown";
    let knowledgeFiles: string[] = [];
    let knowledgeError: string | null = null;
    
    try {
      // Import ƒë·ªông ƒë·ªÉ tr√°nh l·ªói circular dependency
      const { loadKnowledgeBase } = await import("@/lib/knowledge");
      await loadKnowledgeBase();
      knowledgeStatus = "ok";
      
      // Th·ª≠ l·∫•y danh s√°ch t·ªáp trong th∆∞ m·ª•c knowledge
      // S·ª≠ d·ª•ng fs/promises thay v√¨ require
      const fs = await import('fs/promises');
      const path = await import('path');
      const knowledgeDir = path.join(process.cwd(), "knowledge");
      
      try {
        const files = await fs.readdir(knowledgeDir);
        knowledgeFiles = files;
      } catch (fsError) {
        console.error("Error reading knowledge directory:", fsError);
      }
    } catch (knowledgeErr) {
      knowledgeStatus = "error";
      knowledgeError = knowledgeErr instanceof Error ? knowledgeErr.message : String(knowledgeErr);
    }

    return new Response(
      JSON.stringify({
        status: connectionTest.success ? "ok" : "error",
        message: connectionTest.message,
        model: connectionTest.modelTested || MODEL_CONFIG.modelId,
        fallbackModels: MODEL_CONFIG.fallbackModels,
        knowledge: {
          status: knowledgeStatus,
          files: knowledgeFiles,
          error: knowledgeError
        },
        timestamp: new Date().toISOString(),
      }),
      { headers: { "Content-Type": "application/json" } },
    )
  } catch (error) {
    return new Response(
      JSON.stringify({
        status: "error",
        message: "Kh√¥ng th·ªÉ ki·ªÉm tra k·∫øt n·ªëi ƒë·∫øn OpenRouter",
        details: error instanceof Error ? error.message : "Unknown error",
        timestamp: new Date().toISOString(),
      }),
      {
        status: 500,
        headers: { "Content-Type": "application/json" },
      },
    )
  }
}
